{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from summarytools import dfSummary\n",
    "\n",
    "from env_setup import *\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_test = pd.read_csv(fr\"{dataout}//{dataset}_test.csv\")\n",
    "y_test = X_test[['Churned']]\n",
    "X_test.drop(columns=['Churned'], inplace=True)\n",
    "\n",
    "X_train = pd.read_csv(fr\"{dataout}//{dataset}_train.csv\")\n",
    "y_train = X_train[['Churned']]\n",
    "X_train.drop(columns=['Churned'], inplace=True)\n",
    "\n",
    "X_train_sm = pd.read_csv(fr\"{dataout}//{dataset}_SMOTE_train.csv\")\n",
    "y_train_sm = X_train_sm[['Churned']]\n",
    "X_train_sm.drop(columns=['Churned'], inplace=True)\n",
    "\n",
    "X_train_smenn = pd.read_csv(fr\"{dataout}//{dataset}_SMOTEENN_train.csv\")\n",
    "y_train_smenn = X_train_smenn[['Churned']]\n",
    "X_train_smenn.drop(columns=['Churned'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Income', 'Tenure', 'NumSupportCalls', 'NumComplaints',\n",
       "       'Purchase', 'Refund', 'Subscription Renewal', 'Support Fee', 'Upgrade',\n",
       "       'txn_mean', 'txn_count', 'Age_norm', 'Income_norm', 'Tenure_norm',\n",
       "       'NumSupportCalls_norm', 'NumComplaints_norm', 'Purchase_norm',\n",
       "       'Refund_norm', 'Subscription Renewal_norm', 'Support Fee_norm',\n",
       "       'Upgrade_norm', 'txn_mean_norm', 'txn_count_norm', 'Gender_Female',\n",
       "       'Gender_Male', 'Location_Rural', 'Location_Suburban', 'Location_Urban'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original vs Binned columns\n",
    "l_cols_num = [\n",
    "    'Age', 'Income', 'Tenure', 'NumSupportCalls', 'NumComplaints',\n",
    "    'Purchase', 'Refund', 'Subscription Renewal', 'Support Fee', 'Upgrade',\n",
    "    'txn_mean', 'txn_count'\n",
    "    ]\n",
    "\n",
    "l_cols_cat = [\n",
    "    #'Gender_Female', \n",
    "    'Gender_Male', \n",
    "    'Location_Rural', 'Location_Suburban', \n",
    "    #'Location_Urban',\n",
    "    ]\n",
    "\n",
    "l_cols_norm = [\n",
    "    'Age_norm', 'Income_norm', 'Tenure_norm',\n",
    "    'NumSupportCalls_norm', 'NumComplaints_norm', 'Purchase_norm',\n",
    "    'Refund_norm', 'Subscription Renewal_norm', 'Support Fee_norm',\n",
    "    'Upgrade_norm', 'txn_mean_norm', 'txn_count_norm'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm \n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "class logistic_regression:\n",
    "    def __init__(self, y_train, x_train, cols, name, y=y_test, x=X_test):\n",
    "        self.name = name\n",
    "        self.y_train = y_train\n",
    "        self.x_train = x_train\n",
    "        self.y = y_test\n",
    "        self.x = X_test\n",
    "        self.cols = cols\n",
    "        self.model = sm.Logit(self.y_train, self.x_train[cols]).fit()\n",
    "\n",
    "    def summary(self):\n",
    "        print(self.model.summary())\n",
    "\n",
    "    def predict(self, confusion=False):\n",
    "        yhat = self.model.predict(self.x[self.cols]) \n",
    "        prediction = list(map(round, yhat))\n",
    "        self.cm = classification_report(self.y, prediction)\n",
    "        f1 = f1_score(self.y, prediction)\n",
    "        self.f1 = f1\n",
    "        print(f\"{self.name}: F1 = {f1}\")    \n",
    "        if confusion:\n",
    "            print (\"Confusion Matrix : \\n\", self.cm)\n",
    "\n",
    "    def feature_selection(self):\n",
    "        # Remove columns with no statistical differences\n",
    "        try:\n",
    "            self.cols.remove('Age')\n",
    "            self.cols.remove('TransactionDate')\n",
    "            self.cols.remove('NumComplaints')\n",
    "        except:\n",
    "            pass\n",
    "        self.model = sm.Logit(self.y_train, self.x_train[self.cols]).fit()\n",
    "        self.predict()\n",
    "        f1 = self.f1\n",
    "\n",
    "        for i in self.cols:\n",
    "            self.cols.remove(i)\n",
    "            self.model = sm.Logit(self.y_train, self.x_train[self.cols]).fit()\n",
    "            print(self.cols)\n",
    "            self.predict()\n",
    "            new_f1 = self.f1\n",
    "\n",
    "            if new_f1 < f1:\n",
    "                self.cols.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.552082\n",
      "         Iterations 5\n",
      "ori_baseLogit_num: F1 = 0.14115490375802017\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.551979\n",
      "         Iterations 6\n",
      "ori_baseLogit_norm: F1 = 0.19980133390095076\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.613751\n",
      "         Iterations 5\n",
      "sm_baseLogit_num: F1 = 0.4387175017054499\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.615459\n",
      "         Iterations 5\n",
      "sm_baseLogit_norm: F1 = 0.43672000612510525\n",
      "\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.549064\n",
      "         Iterations 6\n",
      "smenn_baseLogit_num: F1 = 0.4639103013314646\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.554466\n",
      "         Iterations 6\n",
      "smenn_baseLogit_norm: F1 = 0.46153846153846156\n"
     ]
    }
   ],
   "source": [
    "ori_baseLogit_num = logistic_regression(y_train, X_train, l_cols_num+l_cols_cat, 'ori_baseLogit_num')\n",
    "ori_baseLogit_num.predict()\n",
    "ori_baseLogit_norm = logistic_regression(y_train, X_train, l_cols_norm+l_cols_cat, 'ori_baseLogit_norm')\n",
    "ori_baseLogit_norm.predict()\n",
    "print('\\n')\n",
    "sm_baseLogit_num = logistic_regression(y_train_sm, X_train_sm, l_cols_num+l_cols_cat, 'sm_baseLogit_num')\n",
    "sm_baseLogit_num.predict()\n",
    "sm_baseLogit_norm = logistic_regression(y_train_sm, X_train_sm, l_cols_norm+l_cols_cat, 'sm_baseLogit_norm')\n",
    "sm_baseLogit_norm.predict()\n",
    "print('\\n')\n",
    "smenn_baseLogit_num = logistic_regression(y_train_smenn, X_train_smenn, l_cols_num+l_cols_cat, 'smenn_baseLogit_num')\n",
    "smenn_baseLogit_num.predict()\n",
    "smenn_baseLogit_norm = logistic_regression(y_train_smenn, X_train_smenn, l_cols_norm+l_cols_cat, 'smenn_baseLogit_norm')\n",
    "smenn_baseLogit_norm.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class decision_tree:\n",
    "    def __init__(self, y_train, x_train, cols, name, y=y_test, x=X_test):\n",
    "        self.name = name\n",
    "        self.y_train = y_train\n",
    "        self.x_train = x_train\n",
    "        self.y = y_test\n",
    "        self.x = X_test\n",
    "        self.cols = cols\n",
    "        self.model = DecisionTreeClassifier().fit(self.x_train[self.cols], self.y_train)\n",
    "\n",
    "    def summary(self):\n",
    "        tree.plot_tree(self.model, feature_names=self.cols)\n",
    "\n",
    "    def predict(self, confusion=False):\n",
    "        yhat = self.model.predict(self.x[self.cols]) \n",
    "        prediction = list(map(round, yhat))\n",
    "        self.cm = classification_report(self.y, prediction)\n",
    "        f1 = f1_score(self.y, prediction)\n",
    "        self.f1 = f1\n",
    "        print(f\"{self.name}: F1 = {f1}\")    \n",
    "        if confusion:\n",
    "            print (\"Confusion Matrix : \\n\", self.cm)\n",
    "\n",
    "    def feature_selection(self):\n",
    "        # Remove columns with no statistical differences\n",
    "        try:\n",
    "            self.cols.remove('Age')\n",
    "            self.cols.remove('TransactionDate')\n",
    "            self.cols.remove('NumComplaints')\n",
    "        except:\n",
    "            pass\n",
    "        self.model = DecisionTreeClassifier().fit(self.x_train[self.cols], self.y_train)\n",
    "        self.predict()\n",
    "        f1 = self.f1\n",
    "\n",
    "        for i in self.cols:\n",
    "            self.cols.remove(i)\n",
    "            self.model = DecisionTreeClassifier().fit(self.x_train[self.cols], self.y_train)\n",
    "            print(self.cols)\n",
    "            self.predict()\n",
    "            new_f1 = self.f1\n",
    "\n",
    "            if new_f1 < f1:\n",
    "                self.cols.append(i)\n",
    "\n",
    "    def fine_tune(self, params):\n",
    "        random_search = GridSearchCV(\n",
    "            DecisionTreeClassifier(),\n",
    "            params, \n",
    "            n_jobs=-1, \n",
    "            cv=5, \n",
    "            scoring='f1_weighted')\n",
    "        \n",
    "        random_search.fit(self.x_train[self.cols], self.y_train)\n",
    "        self.best_params_random = random_search.best_params_\n",
    "        self.best_score_random = random_search.best_score_\n",
    "        self.model = random_search.best_estimator_\n",
    "        self.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori_baseDT_num: F1 = 0.3436960276338515\n",
      "\n",
      "\n",
      "sm_baseDT_num: F1 = 0.3454296473810339\n",
      "\n",
      "\n",
      "smenn_baseDT_num: F1 = 0.38259833134684146\n"
     ]
    }
   ],
   "source": [
    "# Normalisation not required for decision trees\n",
    "ori_baseDT_num = decision_tree(y_train, X_train, l_cols_num+l_cols_cat, 'ori_baseDT_num')\n",
    "ori_baseDT_num.predict()\n",
    "print('\\n')\n",
    "sm_baseDT_num = decision_tree(y_train_sm, X_train_sm, l_cols_num+l_cols_cat, 'sm_baseDT_num')\n",
    "sm_baseDT_num.predict()\n",
    "print('\\n')\n",
    "smenn_baseDT_num = decision_tree(y_train_smenn, X_train_smenn, l_cols_num+l_cols_cat, 'smenn_baseDT_num')\n",
    "smenn_baseDT_num.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "class naive_bayes:\n",
    "    def __init__(self, y_train, x_train, cols, name, y=y_test, x=X_test):\n",
    "        self.name = name\n",
    "        self.y_train = y_train.values.ravel()\n",
    "        self.x_train = x_train\n",
    "        self.y = y_test.values.ravel()\n",
    "        self.x = X_test\n",
    "        self.cols = cols\n",
    "        self.model = GaussianNB().fit(self.x_train[self.cols].values, self.y_train)\n",
    "\n",
    "    def predict(self, confusion=False):\n",
    "        yhat = self.model.predict(self.x[self.cols].values) \n",
    "        prediction = list(map(round, yhat))\n",
    "        self.cm = classification_report(self.y, prediction)\n",
    "        f1 = f1_score(self.y, prediction)\n",
    "        self.f1 = f1\n",
    "        print(f\"{self.name}: F1 = {f1}\")    \n",
    "        if confusion:\n",
    "            print (\"Confusion Matrix : \\n\", self.cm)\n",
    "\n",
    "    def feature_selection(self):\n",
    "        # Remove columns with no statistical differences\n",
    "        try:\n",
    "            self.cols.remove('Age')\n",
    "            self.cols.remove('TransactionDate')\n",
    "            self.cols.remove('NumComplaints')\n",
    "        except:\n",
    "            pass\n",
    "        self.model = GaussianNB().fit(self.x_train[self.cols].values, self.y_train)\n",
    "        self.predict()\n",
    "        f1 = self.f1\n",
    "\n",
    "        for i in self.cols:\n",
    "            self.cols.remove(i)\n",
    "            self.model = GaussianNB().fit(self.x_train[self.cols].values, self.y_train)\n",
    "            print(self.cols)\n",
    "            self.predict()\n",
    "            new_f1 = self.f1\n",
    "\n",
    "            if new_f1 < f1:\n",
    "                self.cols.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori_baseNB_num: F1 = 0.08699855002416626\n",
      "ori_baseNB_norm: F1 = 0.11914761238139679\n",
      "\n",
      "\n",
      "sm_baseNB_num: F1 = 0.49937406109163746\n",
      "sm_baseNB_norm: F1 = 0.41925535915757806\n",
      "\n",
      "\n",
      "smenn_baseNB_num: F1 = 0.4909537412920363\n",
      "smenn_baseNB_norm: F1 = 0.4367558132286017\n"
     ]
    }
   ],
   "source": [
    "ori_baseNB_num = naive_bayes(y_train, X_train, l_cols_num+l_cols_cat, 'ori_baseNB_num')\n",
    "ori_baseNB_num.predict()\n",
    "ori_baseNB_norm = naive_bayes(y_train, X_train, l_cols_norm+l_cols_cat, 'ori_baseNB_norm')\n",
    "ori_baseNB_norm.predict()\n",
    "print('\\n')\n",
    "sm_baseNB_num = naive_bayes(y_train_sm, X_train_sm, l_cols_num+l_cols_cat, 'sm_baseNB_num')\n",
    "sm_baseNB_num.predict()\n",
    "sm_baseNB_norm = naive_bayes(y_train_sm, X_train_sm, l_cols_norm+l_cols_cat, 'sm_baseNB_norm')\n",
    "sm_baseNB_norm.predict()\n",
    "print('\\n')\n",
    "smenn_baseNB_num = naive_bayes(y_train_smenn, X_train_smenn, l_cols_num+l_cols_cat, 'smenn_baseNB_num')\n",
    "smenn_baseNB_num.predict()\n",
    "smenn_baseNB_norm = naive_bayes(y_train_smenn, X_train_smenn, l_cols_norm+l_cols_cat, 'smenn_baseNB_norm')\n",
    "smenn_baseNB_norm.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "class random_forest:\n",
    "    def __init__(self, y_train, x_train, cols, name, y=y_test, x=X_test):\n",
    "        self.name = name\n",
    "        self.y_train = y_train\n",
    "        self.x_train = x_train[cols]\n",
    "        self.y = y_test\n",
    "        self.x = X_test[cols]\n",
    "        self.cols = cols\n",
    "        self.model = RandomForestClassifier(n_estimators = 10).fit(self.x_train[cols], self.y_train)\n",
    "\n",
    "    def summary(self):\n",
    "        tree.plot_tree(self.model, feature_names=self.cols)\n",
    "\n",
    "    def predict(self, confusion=False):\n",
    "        yhat = self.model.predict(self.x[self.cols]) \n",
    "        prediction = list(map(round, yhat))\n",
    "        self.cm = classification_report(self.y, prediction)\n",
    "        f1 = f1_score(self.y, prediction)\n",
    "        self.f1 = f1\n",
    "        print(f\"{self.name}: F1 = {f1}\")    \n",
    "        if confusion:\n",
    "            print (\"Confusion Matrix : \\n\", self.cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori_baseRF_num: F1 = 0.2867976559806963\n"
     ]
    }
   ],
   "source": [
    "# Normalisation and Balancing not required for decision trees\n",
    "ori_baseRF_num = random_forest(y_train_sm, X_train_sm, l_cols_num+l_cols_cat, 'ori_baseRF_num')\n",
    "ori_baseRF_num.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.549064\n",
      "         Iterations 6\n",
      "smenn_FT_Logit_num: F1 = 0.4639103013314646\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.558244\n",
      "         Iterations 6\n",
      "smenn_FT_Logit_num: F1 = 0.45308455565142364\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.570279\n",
      "         Iterations 5\n",
      "['Tenure', 'NumSupportCalls', 'NumComplaints', 'Purchase', 'Refund', 'Subscription Renewal', 'Support Fee', 'Upgrade', 'txn_mean', 'txn_count', 'Gender_Male', 'Location_Rural', 'Location_Suburban']\n",
      "smenn_FT_Logit_num: F1 = 0.4428972366148532\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.562666\n",
      "         Iterations 5\n",
      "['Tenure', 'NumComplaints', 'Purchase', 'Refund', 'Subscription Renewal', 'Support Fee', 'Upgrade', 'txn_mean', 'txn_count', 'Gender_Male', 'Location_Rural', 'Location_Suburban', 'Income']\n",
      "smenn_FT_Logit_num: F1 = 0.4509592584608752\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.558506\n",
      "         Iterations 6\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Subscription Renewal', 'Support Fee', 'Upgrade', 'txn_mean', 'txn_count', 'Gender_Male', 'Location_Rural', 'Location_Suburban', 'Income', 'NumSupportCalls']\n",
      "smenn_FT_Logit_num: F1 = 0.4539136992942951\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.558513\n",
      "         Iterations 6\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Support Fee', 'Upgrade', 'txn_mean', 'txn_count', 'Gender_Male', 'Location_Rural', 'Location_Suburban', 'Income', 'NumSupportCalls']\n",
      "smenn_FT_Logit_num: F1 = 0.45343388095879344\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.558626\n",
      "         Iterations 6\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Support Fee', 'txn_mean', 'txn_count', 'Gender_Male', 'Location_Rural', 'Location_Suburban', 'Income', 'NumSupportCalls']\n",
      "smenn_FT_Logit_num: F1 = 0.45331754829683046\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.566724\n",
      "         Iterations 5\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Support Fee', 'txn_mean', 'Gender_Male', 'Location_Rural', 'Location_Suburban', 'Income', 'NumSupportCalls']\n",
      "smenn_FT_Logit_num: F1 = 0.4515784413225789\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.571945\n",
      "         Iterations 5\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Support Fee', 'txn_mean', 'Gender_Male', 'Location_Suburban', 'Income', 'NumSupportCalls', 'txn_count']\n",
      "smenn_FT_Logit_num: F1 = 0.46439596624819923\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.582841\n",
      "         Iterations 5\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Support Fee', 'txn_mean', 'Gender_Male', 'Location_Suburban', 'NumSupportCalls', 'txn_count']\n",
      "smenn_FT_Logit_num: F1 = 0.452853407168128\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.579568\n",
      "         Iterations 5\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Support Fee', 'txn_mean', 'Gender_Male', 'Location_Suburban', 'NumSupportCalls', 'Income']\n",
      "smenn_FT_Logit_num: F1 = 0.46201566154784907\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.579568\n",
      "         Iterations 5\n",
      "smenn_FT_Logit_num: F1 = 0.46201566154784907\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.609635\n",
      "         Iterations 5\n",
      "['NumComplaints', 'Refund', 'Support Fee', 'txn_mean', 'Gender_Male', 'Location_Suburban', 'NumSupportCalls', 'Income']\n",
      "smenn_FT_Logit_num: F1 = 0.41819950477538026\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.579737\n",
      "         Iterations 5\n",
      "['NumComplaints', 'Support Fee', 'txn_mean', 'Gender_Male', 'Location_Suburban', 'NumSupportCalls', 'Income', 'Tenure']\n",
      "smenn_FT_Logit_num: F1 = 0.46246124129517613\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.583716\n",
      "         Iterations 5\n",
      "['NumComplaints', 'Support Fee', 'Gender_Male', 'Location_Suburban', 'NumSupportCalls', 'Income', 'Tenure']\n",
      "smenn_FT_Logit_num: F1 = 0.45985661259978644\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.587720\n",
      "         Iterations 5\n",
      "['NumComplaints', 'Support Fee', 'Gender_Male', 'NumSupportCalls', 'Income', 'Tenure', 'txn_mean']\n",
      "smenn_FT_Logit_num: F1 = 0.4744039097595893\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.602814\n",
      "         Iterations 5\n",
      "['NumComplaints', 'Support Fee', 'Gender_Male', 'NumSupportCalls', 'Tenure', 'txn_mean']\n",
      "smenn_FT_Logit_num: F1 = 0.45888503444569306\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.591326\n",
      "         Iterations 5\n",
      "['NumComplaints', 'Support Fee', 'Gender_Male', 'NumSupportCalls', 'Tenure', 'Income']\n",
      "smenn_FT_Logit_num: F1 = 0.4679866036249015\n"
     ]
    }
   ],
   "source": [
    "# Feature selection - LR\n",
    "smenn_FT_Logit_num = logistic_regression(y_train_smenn, X_train_smenn, l_cols_num+l_cols_cat, 'smenn_FT_Logit_num')\n",
    "smenn_FT_Logit_num.predict()\n",
    "smenn_FT_Logit_num.feature_selection()\n",
    "smenn_FT_Logit_num.feature_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sm_baseDT_num: F1 = 0.3503239004432322\n",
      "sm_baseDT_num: F1 = 0.34276406035665297\n",
      "['Tenure', 'NumSupportCalls', 'NumComplaints', 'Purchase', 'Refund', 'Subscription Renewal', 'Support Fee', 'Upgrade', 'txn_mean', 'txn_count', 'Gender_Male', 'Location_Rural', 'Location_Suburban']\n",
      "sm_baseDT_num: F1 = 0.34787052810902896\n",
      "['Tenure', 'NumComplaints', 'Purchase', 'Refund', 'Subscription Renewal', 'Support Fee', 'Upgrade', 'txn_mean', 'txn_count', 'Gender_Male', 'Location_Rural', 'Location_Suburban']\n",
      "sm_baseDT_num: F1 = 0.341646737273659\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Subscription Renewal', 'Support Fee', 'Upgrade', 'txn_mean', 'txn_count', 'Gender_Male', 'Location_Rural', 'Location_Suburban', 'NumSupportCalls']\n",
      "sm_baseDT_num: F1 = 0.34203048307930767\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Support Fee', 'Upgrade', 'txn_mean', 'txn_count', 'Gender_Male', 'Location_Rural', 'Location_Suburban', 'NumSupportCalls', 'Purchase']\n",
      "sm_baseDT_num: F1 = 0.34592377371389504\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Support Fee', 'txn_mean', 'txn_count', 'Gender_Male', 'Location_Rural', 'Location_Suburban', 'NumSupportCalls', 'Purchase']\n",
      "sm_baseDT_num: F1 = 0.34605251975864704\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Support Fee', 'txn_mean', 'Gender_Male', 'Location_Rural', 'Location_Suburban', 'NumSupportCalls', 'Purchase']\n",
      "sm_baseDT_num: F1 = 0.3484861407249467\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Support Fee', 'txn_mean', 'Gender_Male', 'Location_Suburban', 'NumSupportCalls', 'Purchase']\n",
      "sm_baseDT_num: F1 = 0.35219911353562905\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Support Fee', 'txn_mean', 'Gender_Male', 'Location_Suburban', 'Purchase']\n",
      "sm_baseDT_num: F1 = 0.345974025974026\n",
      "sm_baseDT_num: F1 = 0.3488110678772157\n",
      "['NumComplaints', 'Refund', 'Support Fee', 'txn_mean', 'Gender_Male', 'Location_Suburban', 'Purchase']\n",
      "sm_baseDT_num: F1 = 0.30583995413219756\n",
      "['NumComplaints', 'Support Fee', 'txn_mean', 'Gender_Male', 'Location_Suburban', 'Purchase', 'Tenure']\n",
      "sm_baseDT_num: F1 = 0.3387208898157803\n",
      "['NumComplaints', 'Support Fee', 'Gender_Male', 'Location_Suburban', 'Purchase', 'Tenure', 'Refund']\n",
      "sm_baseDT_num: F1 = 0.34199629988547264\n",
      "['NumComplaints', 'Support Fee', 'Gender_Male', 'Purchase', 'Tenure', 'Refund', 'txn_mean']\n",
      "sm_baseDT_num: F1 = 0.3444310966191865\n",
      "['NumComplaints', 'Support Fee', 'Gender_Male', 'Purchase', 'Refund', 'txn_mean', 'Location_Suburban']\n",
      "sm_baseDT_num: F1 = 0.30517622045956333\n",
      "['NumComplaints', 'Support Fee', 'Gender_Male', 'Purchase', 'Refund', 'Location_Suburban', 'Tenure']\n",
      "sm_baseDT_num: F1 = 0.339924422181211\n",
      "['NumComplaints', 'Support Fee', 'Gender_Male', 'Purchase', 'Refund', 'Location_Suburban', 'txn_mean']\n",
      "sm_baseDT_num: F1 = 0.3032833865553099\n",
      "['NumComplaints', 'Support Fee', 'Gender_Male', 'Purchase', 'Refund', 'Location_Suburban', 'txn_mean']\n",
      "sm_baseDT_num: F1 = 0.30671135453282106\n"
     ]
    }
   ],
   "source": [
    "# Feature selection - DT\n",
    "ori_FS_DT_num = decision_tree(y_train_sm, X_train_sm, l_cols_num+l_cols_cat, 'sm_baseDT_num')\n",
    "ori_FS_DT_num.predict()\n",
    "ori_FS_DT_num.feature_selection()\n",
    "ori_FS_DT_num.feature_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sm_FT_NB_num: F1 = 0.49937406109163746\n",
      "sm_FT_NB_num: F1 = 0.5026916651197327\n",
      "['Tenure', 'NumSupportCalls', 'NumComplaints', 'Purchase', 'Refund', 'Subscription Renewal', 'Support Fee', 'Upgrade', 'txn_mean', 'txn_count', 'Gender_Male', 'Location_Rural', 'Location_Suburban']\n",
      "sm_FT_NB_num: F1 = 0.42243383069655843\n",
      "['Tenure', 'NumComplaints', 'Purchase', 'Refund', 'Subscription Renewal', 'Support Fee', 'Upgrade', 'txn_mean', 'txn_count', 'Gender_Male', 'Location_Rural', 'Location_Suburban', 'Income']\n",
      "sm_FT_NB_num: F1 = 0.5031151687126025\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Subscription Renewal', 'Support Fee', 'Upgrade', 'txn_mean', 'txn_count', 'Gender_Male', 'Location_Rural', 'Location_Suburban', 'Income']\n",
      "sm_FT_NB_num: F1 = 0.5032289808721323\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Support Fee', 'Upgrade', 'txn_mean', 'txn_count', 'Gender_Male', 'Location_Rural', 'Location_Suburban', 'Income']\n",
      "sm_FT_NB_num: F1 = 0.5054999078227739\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Support Fee', 'txn_mean', 'txn_count', 'Gender_Male', 'Location_Rural', 'Location_Suburban', 'Income']\n",
      "sm_FT_NB_num: F1 = 0.5063197938397349\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Support Fee', 'txn_mean', 'Gender_Male', 'Location_Rural', 'Location_Suburban', 'Income']\n",
      "sm_FT_NB_num: F1 = 0.5065174618789966\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Support Fee', 'txn_mean', 'Gender_Male', 'Location_Suburban', 'Income']\n",
      "sm_FT_NB_num: F1 = 0.5053181563724576\n",
      "['Tenure', 'NumComplaints', 'Refund', 'Support Fee', 'txn_mean', 'Gender_Male', 'Location_Suburban']\n",
      "sm_FT_NB_num: F1 = 0.4476996373462277\n",
      "sm_FT_NB_num: F1 = 0.5053181563724576\n",
      "['NumComplaints', 'Refund', 'Support Fee', 'txn_mean', 'Gender_Male', 'Location_Suburban', 'Income']\n",
      "sm_FT_NB_num: F1 = 0.37470943747094376\n",
      "['NumComplaints', 'Support Fee', 'txn_mean', 'Gender_Male', 'Location_Suburban', 'Income', 'Tenure']\n",
      "sm_FT_NB_num: F1 = 0.5041527209619437\n",
      "['NumComplaints', 'Support Fee', 'Gender_Male', 'Location_Suburban', 'Income', 'Tenure', 'Refund']\n",
      "sm_FT_NB_num: F1 = 0.5094991364421416\n",
      "['NumComplaints', 'Support Fee', 'Gender_Male', 'Income', 'Tenure', 'Refund']\n",
      "sm_FT_NB_num: F1 = 0.5129385419258522\n",
      "['NumComplaints', 'Support Fee', 'Gender_Male', 'Income', 'Refund']\n",
      "sm_FT_NB_num: F1 = 0.3729713423831071\n",
      "['NumComplaints', 'Support Fee', 'Gender_Male', 'Income', 'Refund']\n",
      "sm_FT_NB_num: F1 = 0.3729713423831071\n"
     ]
    }
   ],
   "source": [
    "# Feature selection - NB\n",
    "sm_FT_NB_num = naive_bayes(y_train_sm, X_train_sm, l_cols_num+l_cols_cat, 'sm_FT_NB_num')\n",
    "sm_FT_NB_num.predict()\n",
    "sm_FT_NB_num.feature_selection()\n",
    "sm_FT_NB_num.feature_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.610709\n",
      "         Iterations 5\n",
      "LR_model: F1 = 0.45481897502758\n",
      "Confusion Matrix : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.32      0.46     14384\n",
      "           1       0.32      0.81      0.45      5616\n",
      "\n",
      "    accuracy                           0.46     20000\n",
      "   macro avg       0.56      0.56      0.46     20000\n",
      "weighted avg       0.67      0.46      0.46     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "LR_model = logistic_regression(y_train_smenn, X_train_smenn, ['NumComplaints', 'Gender_Male', 'NumSupportCalls', 'Tenure'], 'LR_model')\n",
    "LR_model.predict(confusion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                Churned   No. Observations:                54333\n",
      "Model:                          Logit   Df Residuals:                    54329\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Thu, 29 Aug 2024   Pseudo R-squ.:                 0.01477\n",
      "Time:                        04:40:50   Log-Likelihood:                -33563.\n",
      "converged:                       True   LL-Null:                       -34066.\n",
      "Covariance Type:            nonrobust   LLR p-value:                6.682e-218\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "NumComplaints       0.2698      0.006     42.020      0.000       0.257       0.282\n",
      "Gender_Male        -0.3061      0.018    -16.581      0.000      -0.342      -0.270\n",
      "NumSupportCalls     0.1543      0.003     50.249      0.000       0.148       0.160\n",
      "Tenure             -0.1220      0.003    -36.728      0.000      -0.129      -0.116\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "LR_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT_model: F1 = 0.325469888761028\n",
      "Confusion Matrix : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76     14384\n",
      "           1       0.35      0.30      0.33      5616\n",
      "\n",
      "    accuracy                           0.65     20000\n",
      "   macro avg       0.55      0.54      0.54     20000\n",
      "weighted avg       0.63      0.65      0.64     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "DT_model = decision_tree(y_train_sm, X_train_sm, ['NumComplaints', 'Gender_Male', 'Tenure', 'Refund'], 'DT_model')\n",
    "DT_model.predict(confusion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB_model: F1 = 0.5039654394222709\n",
      "Confusion Matrix : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.58      0.69     14384\n",
      "           1       0.40      0.70      0.50      5616\n",
      "\n",
      "    accuracy                           0.62     20000\n",
      "   macro avg       0.61      0.64      0.59     20000\n",
      "weighted avg       0.71      0.62      0.63     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "NB_model = naive_bayes(y_train_sm, X_train_sm, ['NumComplaints', 'Gender_Male', 'Tenure'], 'NB_model')\n",
    "NB_model.predict(confusion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori_FT_DT_num: F1 = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter distribution to sample from\n",
    "param_dist = {'criterion':['gini','entropy'],\n",
    "              'max_depth':np.arange(1,10).tolist()[0::2],\n",
    "              'min_samples_split':np.arange(100,200).tolist()[0::2],\n",
    "              'max_leaf_nodes':np.arange(3,10).tolist()[0::2]}\n",
    "\n",
    "ori_FT_DT_num = decision_tree(y_train, X_train, ['NumSupportCalls', 'TransactionType_Refund', 'Income', 'Tenure', 'Location_Rural'], 'ori_FT_DT_num')\n",
    "ori_FT_DT_num.fine_tune(param_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 15, 'max_leaf_nodes': 17, 'min_samples_split': np.float64(0.018242481428361046)}\n",
      "\n",
      "\n",
      "0.6036802569001319\n"
     ]
    }
   ],
   "source": [
    "print(ori_FT_DT_num.best_params_random)\n",
    "print('\\n')\n",
    "print(ori_FT_DT_num.best_score_random)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
