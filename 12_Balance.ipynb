{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from summarytools import dfSummary\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from env_setup import *\n",
    "from functions.t_test import *\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_raw = pd.read_csv(fr\"{dataout}//{dataset}_FE.csv\")\n",
    "df_raw.head()\n",
    "df_ori = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: Gender, Location, TransactionType, Age_bin, Income_bin, Tenure_bin, TransactionDate_bin, TransactionAmount_bin\n",
      "Numeric columns: Age, Income, Tenure, TransactionDate, TransactionAmount, NumSupportCalls, NumComplaints, Age_norm, Income_norm, Tenure_norm, TransactionDate_norm, TransactionAmount_norm, NumSupportCalls_norm, NumComplaints_norm, Gender_Female, Gender_Male, Location_Rural, Location_Suburban, Location_Urban, TransactionType_Purchase, TransactionType_Refund, TransactionType_Subscription Renewal, TransactionType_Support Fee, TransactionType_Upgrade, Age_bin_(0, 10], Age_bin_(10, 20], Age_bin_(20, 30], Age_bin_(30, 40], Age_bin_(40, 50], Age_bin_(50, 60], Age_bin_(60, 70], Income_bin_(0, 10000], Income_bin_(10000, 20000], Income_bin_(20000, 30000], Income_bin_(30000, 40000], Income_bin_(40000, 50000], Income_bin_(50000, 60000], Income_bin_(60000, 70000], Income_bin_(70000, 80000], Income_bin_(80000, 90000], Income_bin_(90000, 100000], Income_bin_(100000, 110000], Income_bin_(110000, 120000], Income_bin_(120000, 130000], Income_bin_(130000, 140000], Income_bin_(140000, 150000], Income_bin_(150000, 160000], Income_bin_(160000, 170000], Income_bin_(170000, 180000], Income_bin_(180000, 190000], Tenure_bin_(0, 5], Tenure_bin_>5, TransactionDate_bin_(0, 30], TransactionDate_bin_(30, 60], TransactionDate_bin_(60, 90], TransactionDate_bin_(90, 120], TransactionDate_bin_(120, 150], TransactionDate_bin_(150, 180], TransactionDate_bin_(180, 210], TransactionDate_bin_(210, 240], TransactionDate_bin_(240, 270], TransactionDate_bin_(270, 300], TransactionDate_bin_(300, 330], TransactionDate_bin_(330, 360], TransactionAmount_bin_(0, 100], TransactionAmount_bin_(100, 200], TransactionAmount_bin_(200, 300], TransactionAmount_bin_(300, 400], TransactionAmount_bin_(400, 500]\n"
     ]
    }
   ],
   "source": [
    "# Split categorical and numeric\n",
    "l_cols_cat = [i for i in df_ori if df_ori[i].dtype==object]\n",
    "l_cols_num = [i for i in df_ori if df_ori[i].dtype!=object and i != 'Churned']\n",
    "\n",
    "print(f\"Categorical columns: {', '.join(l_cols_cat)}\")\n",
    "print(f\"Numeric columns: {', '.join(l_cols_num)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove categorical columns\n",
    "df_ori.drop(columns=l_cols_cat, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "x = df_ori.drop(columns=['Churned'])\n",
    "y = df_ori['Churned']\n",
    "X_train,X_test,y_train,y_test=train_test_split(x, y, train_size=0.8, stratify = y, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Synthetic minority over-sampling technique (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 574149, 1: 223955})\n",
      "After Counter({0: 574149, 1: 574149})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y_train)\n",
    "print('Before', counter)\n",
    "\n",
    "# oversampling the train dataset using SMOTE\n",
    "smt = SMOTE()\n",
    "X_train_sm, y_train_sm = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "counter = Counter(y_train_sm)\n",
    "print('After', counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. SMOTE + ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 574149, 1: 223955})\n",
      "After Counter({1: 388751, 0: 256798})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y_train)\n",
    "print('Before',counter)\n",
    "# oversampling the train dataset using SMOTE + ENN\n",
    "smenn = SMOTEENN()\n",
    "X_train_smenn, y_train_smenn = smenn.fit_resample(X_train, y_train)\n",
    "\n",
    "counter = Counter(y_train_smenn)\n",
    "print('After',counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Churned'] = y_test\n",
    "X_test.to_csv(fr\"{dataout}//{dataset}_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm['Churned'] = y_train_sm\n",
    "X_train_sm.to_csv(fr\"{dataout}//{dataset}_SMOTE_train.csv\", index=False)\n",
    "\n",
    "X_train_smenn['Churned'] = y_train_smenn\n",
    "X_train_smenn.to_csv(fr\"{dataout}//{dataset}_SMOTEENN_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
